{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TurboLoader Quick Start Guide\n",
    "\n",
    "Welcome to TurboLoader! This notebook will guide you through the basics of using TurboLoader for high-performance ML data loading.\n",
    "\n",
    "## What is TurboLoader?\n",
    "\n",
    "TurboLoader is a production-ready data loading library that provides:\n",
    "- **Fast**: 8,000+ images/sec with SIMD-accelerated transforms\n",
    "- **Efficient**: Memory-mapped I/O and zero-copy operations\n",
    "- **Easy**: Drop-in replacement for PyTorch DataLoader\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "If you haven't installed TurboLoader yet, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install turboloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Data Loading\n",
    "\n",
    "Let's start with the simplest example - loading images from a TAR archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turboloader\n",
    "import numpy as np\n",
    "\n",
    "print(f\"TurboLoader version: {turboloader.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "loader = turboloader.DataLoader(\n",
    "    'path/to/your/dataset.tar',  # Path to TAR archive\n",
    "    batch_size=32,                # Samples per batch\n",
    "    num_workers=4,                # Parallel worker threads\n",
    "    shuffle=False                 # Shuffle data (for training)\n",
    ")\n",
    "\n",
    "# Iterate over batches\n",
    "for batch in loader:\n",
    "    # Each batch is a list of samples\n",
    "    print(f\"Batch size: {len(batch)}\")\n",
    "    \n",
    "    # Access first sample\n",
    "    sample = batch[0]\n",
    "    image = sample['image']  # NumPy array (H, W, C)\n",
    "    \n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "    print(f\"Image dtype: {image.dtype}\")\n",
    "    \n",
    "    break  # Just load one batch for demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Transforms\n",
    "\n",
    "TurboLoader provides 19 SIMD-accelerated transforms for data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transform pipeline\n",
    "transforms = turboloader.Compose([\n",
    "    turboloader.Resize(256, 256),              # Resize to 256x256\n",
    "    turboloader.RandomCrop(224, 224),          # Random crop to 224x224\n",
    "    turboloader.RandomHorizontalFlip(0.5),     # Flip with 50% probability\n",
    "    turboloader.ColorJitter(0.2, 0.2, 0.2, 0.1), # Color augmentation\n",
    "    turboloader.ImageNetNormalize()            # ImageNet normalization\n",
    "])\n",
    "\n",
    "print(\"Transform pipeline created!\")\n",
    "print(f\"Number of transforms: {len(transforms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transforms manually\n",
    "loader = turboloader.DataLoader(\n",
    "    'path/to/your/dataset.tar',\n",
    "    batch_size=16,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "for batch in loader:\n",
    "    # Apply transforms to each sample\n",
    "    transformed_images = []\n",
    "    for sample in batch:\n",
    "        img = sample['image']\n",
    "        # Apply each transform in sequence\n",
    "        for transform in transforms:\n",
    "            img = transform.apply(img)\n",
    "        transformed_images.append(img)\n",
    "    \n",
    "    print(f\"Processed {len(transformed_images)} images\")\n",
    "    print(f\"Transformed shape: {transformed_images[0].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PyTorch Integration\n",
    "\n",
    "TurboLoader integrates seamlessly with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create DataLoader\n",
    "loader = turboloader.DataLoader(\n",
    "    'path/to/your/dataset.tar',\n",
    "    batch_size=64,\n",
    "    num_workers=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "to_tensor = turboloader.ToTensor(\n",
    "    format=turboloader.TensorFormat.PYTORCH_CHW  # Convert to (C, H, W)\n",
    ")\n",
    "\n",
    "# Simple training loop\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(3):\n",
    "    for batch in loader:\n",
    "        # Convert to tensors\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for sample in batch:\n",
    "            img = to_tensor.apply(sample['image'])\n",
    "            images.append(torch.from_numpy(img))\n",
    "            labels.append(sample.get('label', 0))  # Default label\n",
    "        \n",
    "        images = torch.stack(images).float().to(device)\n",
    "        labels = torch.tensor(labels).long().to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "        break  # Just one batch for demo\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Comparison\n",
    "\n",
    "Let's compare TurboLoader vs PyTorch DataLoader performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_dataloader(loader, num_batches=100):\n",
    "    \"\"\"Benchmark data loading speed.\"\"\"\n",
    "    start = time.time()\n",
    "    samples = 0\n",
    "    \n",
    "    for i, batch in enumerate(loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        samples += len(batch)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    throughput = samples / elapsed\n",
    "    \n",
    "    return throughput, elapsed\n",
    "\n",
    "# Benchmark TurboLoader\n",
    "loader = turboloader.DataLoader(\n",
    "    'path/to/your/dataset.tar',\n",
    "    batch_size=32,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "throughput, time_taken = benchmark_dataloader(loader)\n",
    "print(f\"\\nTurboLoader Performance:\")\n",
    "print(f\"  Throughput: {throughput:.1f} images/sec\")\n",
    "print(f\"  Time: {time_taken:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Features\n",
    "\n",
    "### Distributed Training\n",
    "\n",
    "TurboLoader supports distributed training with deterministic sharding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For distributed training (multi-GPU)\n",
    "import torch.distributed as dist\n",
    "\n",
    "# Initialize distributed training\n",
    "# dist.init_process_group(backend='nccl')\n",
    "\n",
    "# Create distributed loader\n",
    "loader = turboloader.DataLoader(\n",
    "    'path/to/your/dataset.tar',\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    enable_distributed=True,\n",
    "    # world_rank=dist.get_rank(),\n",
    "    # world_size=dist.get_world_size(),\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(\"Distributed DataLoader configured!\")\n",
    "print(\"Each rank will automatically get its own shard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBL v2 Format\n",
    "\n",
    "Convert TAR archives to TurboLoader's optimized binary format for even faster loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TAR to TBL v2\n",
    "writer = turboloader.TblWriterV2(\n",
    "    output_path=\"dataset.tbl\",\n",
    "    compression=True  # Enable LZ4 compression\n",
    ")\n",
    "\n",
    "# Read from TAR and write to TBL\n",
    "reader = turboloader.DataLoader('input.tar', batch_size=1, num_workers=1)\n",
    "\n",
    "for batch in reader:\n",
    "    for sample in batch:\n",
    "        writer.add_sample(\n",
    "            data=sample['image'],\n",
    "            format=turboloader.SampleFormat.JPEG,\n",
    "            metadata={'label': sample.get('label', 0)}\n",
    "        )\n",
    "\n",
    "writer.finalize()\n",
    "print(\"Conversion complete!\")\n",
    "print(\"TBL format provides 40-60% space savings with LZ4 compression.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "1. âœ… Create a basic DataLoader\n",
    "2. âœ… Apply SIMD-accelerated transforms\n",
    "3. âœ… Integrate with PyTorch training loops\n",
    "4. âœ… Benchmark performance\n",
    "5. âœ… Use advanced features (distributed training, TBL format)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Check out more examples in the `examples/` directory\n",
    "- Read the [documentation](https://github.com/ALJainProjects/TurboLoader)\n",
    "- Run benchmarks to see performance on your data\n",
    "- Join the community discussions\n",
    "\n",
    "Happy training! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
